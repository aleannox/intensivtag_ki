{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on: Ziffernklassifizierung (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Hands-On werden wir ein neuronale Netz trainieren, das handschriftliche Ziffern erkennt. Basis ist die MNIST Database (Modified National Institute of Standards and Technology database). MNIST wurde im Jahr 1998 veröffentlich und ist seitdem ein Klassiker des Maschinellen Lernens und wird in vielen Kursen zum Einstieg in die Verarbeitung und Klassifikation von Bildern verwendet. Auch in wissenschaftlichen Veröffentlichungen ist es immer noch ein Standard, an dem viele Verfahren (insbesondere aus dem Bereich der Bildverarbeitung) beweisen müssen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden wir ein einfaches neuronales Netzwerk bauen, das eine gute Leistung auf MNIST erzielt. Dies zeigt zugleich die Fortschritte und das Potenzial des Deep Learnings. Die hier mit wenigen Zeilen Code erreichten Ergebnisse sind viel besser, als sie selbst die ausgefeiltesten traditionallen Verfahren noch vor wenigen Jahren erreichten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten besorgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entsprechend seinem Referenzstatus wird MNIST direkt durch die Keras-Bibliothek zur Verfügung gestellt und kann mit einer Codezeile eingelesen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.datasets.mnist\n",
    "\n",
    "(raw_train_images, raw_train_labels), (raw_test_images, raw_test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Struktur der Labels:\", raw_train_labels.shape)\n",
    "print(\"Struktur der Bilddaten:\", raw_train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Die Trainingsdaten umfassen 60.000 Ziffern, die jeweils aus 28x28 Grauwerten bestehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns nun eines der Bilder an. Schaut euch auch ein paar andere Beispiele an, indem ihr den Index (Variable `example_nr`) anpasst. Was fällt euch z.B. beim Beispiel mit dem Index 42 auf? Als welche Ziffer hättet ihr das Bild klassifiziert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "example_nr = 12\n",
    "matplotlib.pyplot.imshow(raw_train_images[example_nr], cmap=matplotlib.pyplot.cm.binary)\n",
    "print(\"Label:\", raw_train_labels[example_nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline-Modell\n",
    "\n",
    "Wir starten nun mit einem sehr einfachen neuronalen Netzwerk als Referenz, das nur einen einzigen \"hidden layer\" mit 512 Neuronen enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "import keras.layers\n",
    "\n",
    "network = keras.models.Sequential()\n",
    "network.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "network.add(keras.layers.Dense(32, activation=\"relu\"))\n",
    "network.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "network.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wie man sieht, besteht das Netzwerk nun aus drei Schichten: Input, Hidden Layer und Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenaufbereitung\n",
    "\n",
    "Wie man sieht, besitzt die Ausgabeschicht 10 Neuronen (Output Shape = (None, 10) in der Zusammenfassung). Bei neuronalen Netzen ist es allgemein üblich, dass man bei Klassifizierungsaufgaben soviele Ausgabeneuronen nutzt, wie es Klassen gibt. Effektiv gibt es für jede Ziffer ein Ausgabeneuron, das sich umso stärker meldet, je sicherer es ist, \"seine\" Klasse erkannt zu haben.\n",
    "\n",
    "Das bedeutet, dass wir die Daten noch umformen müssen, damit die Trainingsdaten auch diese Struktur erhalten. Konkret sieht die Umformung wie folgt aus:\n",
    "\n",
    "```\n",
    "0 -> (1, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "1 -> (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "2 -> (0, 0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
    "```\n",
    "usw.\n",
    "\n",
    "Diese Transformation heißt \"One-Hot\" Encoding, da immer genau ein Element des Vektors gefüllt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "\n",
    "train_labels = keras.utils.to_categorical(raw_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir überprüfen, ob alles so geklappt hat wie beschrieben. Auch hier solltet ihr ein paar andere Beispiele betrachten, indem ihr den Wert von `example_nr` anpasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_nr = 42\n",
    "print(raw_train_labels[example_nr], \"->\", train_labels[example_nr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich normieren wir noch den Bereich der Grauwerte von 0 bis 255 (Integer-Werte) auf den Bereich 0 bis 1 (Gleitkommazahlen), da das neuronale Netz intern mit Gleitkommazahlen arbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = raw_train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# Setzen der Startwerte für den beim Training benutzten Zufallszahlengenerator\n",
    "tensorflow.set_random_seed(4242)\n",
    "numpy.random.seed(4242)\n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training läuft (bedingt durch die einfache Architektur) sehr schnell. Trotzdem erreichen wir schon eine Genauigkeit von respektablen 95% auf den Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung\n",
    "\n",
    "Nun überprüfen wir, ob wir auf den Testdaten ähnlich gute Ergebnisse erzielen. Ein Abfall der Güte würde zeigen, dass ein Overfitting vorliegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = raw_test_images.astype(\"float32\") / 255\n",
    "test_labels = keras.utils.to_categorical(raw_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_loss, baseline_accuracy = network.evaluate(test_images, test_labels)\n",
    "baseline_loss, baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Etwa 95% der Test-Ziffern wurden korrekt klassifiziert (bei einem Loss von ca. 0.15). Damit haben wir die Genauigkeit auch auf dem Testset bestätigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "\n",
    "Wir machen jetzt sogenanntes \"Hyperparameter-Tuning\", d.h. wir verändern gezielt Parameter der Architektur und des Lernverfahrens, um eine möglichst hohe Genauigkeit zu erzielen.\n",
    "\n",
    "Bei unserem Modell oben hatten wir 32 Neuronen für den Hidden Layer gewählt. Das war eine willkürliche Wahl. Wir probieren jetzt systematisch unterschiedliche Größen (einige Zweipotenzen zwischen 2 und 4096) für die Anzahl der Neuronen, um zu prüfen, für welche Anzahl wir die besten Ergebnisse bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# Reduktion der Trainingsdaten um den Effekt bei geringer Trainingsdauer sichtbar zu machen\n",
    "train_images_subset = train_images[:30000]\n",
    "train_labels_subset = train_labels[:30000]\n",
    "\n",
    "\n",
    "# Definition eines Arbeitsschrittes, um zu gegebener Netzwerkgröße die Kosten auszurechnen\n",
    "def loss(hidden_unit_count):\n",
    "    tensorflow.set_random_seed(4242)\n",
    "    numpy.random.seed(4242)\n",
    "    network = keras.models.Sequential()\n",
    "    network.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    network.add(keras.layers.Dense(hidden_unit_count, activation=\"relu\"))\n",
    "    network.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    network.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    epochs = 2 + int(math.log(hidden_unit_count, 16) ** 2)\n",
    "    network.fit(train_images_subset, train_labels_subset, epochs=epochs, batch_size=128, verbose=False)\n",
    "    \n",
    "    print(\n",
    "        f\"with {hidden_unit_count:5} hidden units: \",\n",
    "        end=''\n",
    "    )\n",
    "    \n",
    "    train_loss, train_accuracy = network.evaluate(train_images_subset, train_labels_subset, verbose=False)\n",
    "    test_loss, test_accuracy = network.evaluate(test_images, test_labels, verbose=False)\n",
    "    \n",
    "    print(\n",
    "        f\"training accuracy={train_accuracy:.1%}, loss={train_loss:.4f}, \"\n",
    "        f\"test accuracy={test_accuracy:.1%}, loss={test_loss:.4f}\"\n",
    "    )\n",
    "    return train_accuracy, test_accuracy, train_loss, test_loss\n",
    "\n",
    "# Berechnen der Kosten für verschiedene Netzwerkgrößen\n",
    "hidden_unit_counts = [2, 4, 16, 64, 128, 512, 1024, 4096]\n",
    "%time losses = [loss(x) for x in hidden_unit_counts]\n",
    "train_accuracies, test_accuracies, train_losses, test_losses = list(zip(*losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wie man sieht, nimmt die Genauigkeit mit einer zunehmen Anzahl an Neuronen zu. Ganz am Ende sieht man jedoch, dass für das Validation Set der Loss wieder zunimmt und die Genauigkeit sinkt. Damit sind wir im Bereich des Overfittings.\n",
    "\n",
    "Wir stellen die Ergebnisse nun graphisch dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der Ergebnisse\n",
    "\n",
    "matplotlib.pyplot.plot(hidden_unit_counts, train_losses, \":g\", label=\"training\")\n",
    "matplotlib.pyplot.plot(hidden_unit_counts, test_losses, \"g\", label=\"test\")\n",
    "matplotlib.pyplot.xscale(\"log\")\n",
    "matplotlib.pyplot.ylabel(\"loss\")\n",
    "matplotlib.pyplot.axhline(baseline_loss, color=\"b\", linestyle=\"--\", label=\"baseline\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "matplotlib.pyplot.plot(hidden_unit_counts, train_accuracies, \":g\", label=\"training\")\n",
    "matplotlib.pyplot.plot(hidden_unit_counts, test_accuracies, \"g\", label=\"test\")\n",
    "matplotlib.pyplot.xscale(\"log\")\n",
    "matplotlib.pyplot.xlabel(\"hidden units\")\n",
    "matplotlib.pyplot.ylabel(\"accuracy\")\n",
    "matplotlib.pyplot.axhline(baseline_accuracy, color=\"b\", linestyle=\"--\", label=\"baseline\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir zoomen noch etwas weiter in den Plot rein, um den Effekt des Overfittings besser auflösen zu können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(hidden_unit_counts, train_accuracies, \":g\", label=\"training\")\n",
    "matplotlib.pyplot.plot(hidden_unit_counts, test_accuracies, \"g\", label=\"test\")\n",
    "matplotlib.pyplot.xscale(\"log\")\n",
    "matplotlib.pyplot.xlabel(\"hidden units\")\n",
    "matplotlib.pyplot.ylabel(\"loss\")\n",
    "matplotlib.pyplot.ylim(0.9, 1)\n",
    "matplotlib.pyplot.axhline(baseline_accuracy, color=\"b\", linestyle=\"--\", label=\"baseline\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf dieser Basis würden wir einen Wert um die 4096 Neuronen für unser finales Modell wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives Modell\n",
    "\n",
    "Zum Abschluss erproben wir nun einen noch deutlich leistungsfähigeren Ansatz, ein sogenanntes \"Convolutional Neural Network\". Dieses ist speziell an die 2D-Struktur von Bilddaten angepasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = keras.models.Sequential()\n",
    "convnet.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "convnet.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "convnet.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "convnet.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "convnet.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "convnet.add(keras.layers.Dropout(0.25))\n",
    "convnet.add(keras.layers.Flatten())\n",
    "convnet.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "convnet.add(keras.layers.Dropout(0.5))\n",
    "convnet.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "convnet.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Wie man sieht, ist dieses Netzwerk vom Aufbau auch schon deutlich komplizierter.\n",
    "\n",
    "Wir trainieren das Netzwerk nun auf unseren Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen der Startwerte für den beim Training benutzten Zufallszahlengenerator\n",
    "tensorflow.set_random_seed(4242)\n",
    "numpy.random.seed(4242)\n",
    "\n",
    "convnet.fit(\n",
    "    numpy.expand_dims(train_images, axis=-1),\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun überprüfen wir die Genauigkeit auf den Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet_loss, convnet_accuracy = convnet.evaluate(\n",
    "    numpy.expand_dims(test_images, -1),\n",
    "    test_labels\n",
    ")\n",
    "convnet_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erreichen eine Genauigkeit von sehr guten 99,2%. Wir fügen dieses Ergebnis in die Abbildung von oben ein, zusammen mit dem aktuell besten Modell aus der Forschung ('dropconnect')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(hidden_unit_counts, test_accuracies, \"g\", label=\"naive net\")\n",
    "matplotlib.pyplot.xscale(\"log\")\n",
    "matplotlib.pyplot.xlabel(\"hidden units\")\n",
    "matplotlib.pyplot.ylabel(\"accuracy\")\n",
    "matplotlib.pyplot.ylim(.95, 1.0)\n",
    "matplotlib.pyplot.axhline(baseline_accuracy, color=\"b\", linestyle=\"--\", label=\"baseline\")\n",
    "matplotlib.pyplot.axhline(convnet_accuracy, color=\"c\", linestyle=\"-\", label=\"convnet\")\n",
    "matplotlib.pyplot.axhline(0.9979, color=\"r\", linestyle=\"--\", label=\"dropconnect\")\n",
    "matplotlib.pyplot.legend()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, ist das Convolutional Neural Network (\"convnet\") auch deutlich besser als unser bestes bisheriges Netzwerk. Auch hier könnte man natürlich wieder die Hyperparameter optimieren, um z.B. die Größe der verschiedenen Zwischenschichten anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir geben uns jetzt die aus Sicht unser besten Modells 'perfekten' Ziffer-Bilder aus. In diesem Fall hier kann man sie als als \"Durchschnitt\" über alle entsprechenden Ziffern in den Trainingsdaten interpretieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vis.visualization\n",
    "import vis.utils\n",
    "\n",
    "convnet_visualization = keras.models.clone_model(convnet)\n",
    "convnet_visualization.layers[-1].activation = keras.activations.linear\n",
    "convnet_visualization = vis.utils.utils.apply_modifications(convnet_visualization)\n",
    "convnet_visualization.set_weights(convnet.get_weights())\n",
    "\n",
    "for i in range(10):\n",
    "    matplotlib.pyplot.title(f\"{i}\")\n",
    "    matplotlib.pyplot.imshow(\n",
    "        vis.visualization.visualize_activation(\n",
    "            convnet_visualization,\n",
    "            layer_idx=-1,\n",
    "            filter_indices=i,\n",
    "            tv_weight=10.0,\n",
    "            lp_norm_weight=0.0,\n",
    "            input_range=(0., 1.)\n",
    "        )[..., 0],\n",
    "        cmap=matplotlib.pyplot.cm.binary,\n",
    "    )\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich können wir wieder analog zum Hunde & Katzen Modell aus dem Einführungsvortrag ausgeben lassen, auf welche Bereiche des Bildes das Modell abhängig von der möglichen Vorhersageziffer schaut. Mit ein bischen Phantasie kann man sehen, dass das Modell z.B. bei der Beurteilung, ob es sich um eine 3 handelt, nur auf die Bereiche schaut, die bei einer 3 schwarz wären.\n",
    "\n",
    "Ihr könnt gerne die Variable `example_nr` anders belegen und experimentieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(image):\n",
    "    matplotlib.pyplot.figure(figsize=(20, 10))\n",
    "    matplotlib.pyplot.subplot(3, 4, 1)\n",
    "    matplotlib.pyplot.imshow(image, cmap=matplotlib.pyplot.cm.binary)\n",
    "    \n",
    "    for kind in range(10):\n",
    "        matplotlib.pyplot.subplot(3, 4, kind + 2)\n",
    "        matplotlib.pyplot.imshow(\n",
    "            vis.visualization.visualize_saliency(\n",
    "                convnet_visualization,\n",
    "                layer_idx=-1,\n",
    "                filter_indices=kind,\n",
    "                backprop_modifier=\"guided\",\n",
    "                seed_input=image.reshape(28, 28, 1),\n",
    "            ),\n",
    "            cmap=matplotlib.pyplot.cm.jet\n",
    "        )\n",
    "        matplotlib.pyplot.title(kind)\n",
    "    \n",
    "    prediction = convnet.predict(image.reshape(1, 28, 28, 1))[0]\n",
    "    matplotlib.pyplot.subplot(3, 4, 12)\n",
    "    matplotlib.pyplot.bar(range(10), prediction, tick_label=range(10))\n",
    "    matplotlib.pyplot.title(numpy.argmax(prediction))\n",
    "    \n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "example_nr = 1337\n",
    "\n",
    "plot_attention(test_images[example_nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = numpy.argmax(convnet.predict(numpy.expand_dims(test_images, axis=-1)), axis=1)\n",
    "pred_errors = numpy.nonzero(pred != raw_test_labels)[0]\n",
    "\n",
    "for test_nr in pred_errors:\n",
    "    matplotlib.pyplot.imshow(raw_test_images[test_nr], cmap=matplotlib.pyplot.cm.binary)\n",
    "    matplotlib.pyplot.show()\n",
    "    print(\"Label:\", raw_test_labels[test_nr], \"Prediction:\", pred[test_nr], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
