{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model zur Bonitätsanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook widmen wir uns der klassischen Disziplin von KI in Banken, der Entwicklung von Scoringmodellen zur Bonitätsbewertung. Wir nutzen hierfür einen Datensatz von Kreditkartennutzern und versuchen, den Ausfall bzw. Nichtausfall der Kunden vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Laden der Bibliotheken und Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bisect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.environ['DATASET_PATH']\n",
    "ds = pd.read_csv(dataset_path + '/finance/credit card defaults_train.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ds.drop(['id', 'default'], axis=1)\n",
    "y_train = ds.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erster, naiver Versuch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst trainieren wir einfach mit den Daten ohne jegliche Aufbereitung eine logistische Regression. Dies ergibt eine Fehlermeldung, da nicht alle Felder numerisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit korrekten, quantitativen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich sind die Felder \"education\" und \"sex\" qualitative Felder und können daher nicht vearbeitet werden. Wir transformieren sie daher in Dummy-Spalten. Diese neuen Spalten enthalten je nach Ausprägung eine Null oder eine Eins und sind damit valide quantiative Eingangsgrößen für eine logistische Regression. Die Transformation in Dummy-Werte wird auch One-Hot-Encoding genannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummies = pd.get_dummies(X_train, columns=['education', 'sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis der Transformation sieht man in den neuen Spalten ganz rechts im Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir eine logistische Regression durchführen und erhalten eine mäßige AUC von 65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(X_train_dummies, y_train)\n",
    "\n",
    "_ = plot_roc_curve(lm, X_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit einer logistischen Regression können wir nicht-lineare (wie z.B. nicht-monotone oder nicht-gleichmäßige) Einflüsse prinzipienbedingt nicht abbilden. Daher nutzt man oft das sogenannte \"Binning\", mit dem der Wertebereich einer Variablen in mehrere Intervalle unterteilt wird und der Effekt für die Intervalle separat modelliert wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst führen wir ein Binning des Alters durch und beschränken uns dabei vorerst nur auf diese Variable (ein sogenanntes univariates Modell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariates Modell für das Alter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An der ROC-Kurve sehen wir, dass der Einfluss des Alters nicht-monoton ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(X_train[['age']], y_train)\n",
    "_ = plot_roc_curve(lm, X_train[['age']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns den vorhandenen Wertebereich an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.age.min(), X_train.age.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen zerlegen wir mit Stützpunkten in 8 Intervalle: <= 24, 25-29, 30-34, 35-39, 40-49, 50-59, 60-69 und >= 70. Auch diese Intevalle stellen wir über Dummy-Variablen dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_binned = np.digitize(X_train.age, [25, 30, 35, 40, 50, 60, 70])\n",
    "age_dummies = pd.get_dummies(age_binned, prefix='age_bin')\n",
    "age_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns die Wirkungsweise noch einmal genauer an, indem wir das Alter links neben die Dummy-Matrix stellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([X_train.age, age_dummies], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariates Modell für das Alter mit Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun nutzen wir unsere neu gebauten Bins, um unser Modell zu verfeinern. Tatsächlich sehen wir nun einen (kleinen) Effekt mit einer AUC von 53%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(age_dummies, y_train)\n",
    "_ = plot_roc_curve(lm, age_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den beobachteten nicht-monotonen Zusammenhang können wir nun direkt an den Regressionskoeffizienten ablesen. Wir sehen, dass sowohl geringes wie hohes Alter mit einer höheren Ausfallwahrscheinlichkeit einhergeht. Der kleinste Wert liegt bei Bin Nummer 2, also dem Intevall 30-34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(lm.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment_delay_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie oben verfahren wir nun für die Variable \"payment_delay_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariates Modell für payment_delay_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(X_train[['payment_delay_0']], y_train)\n",
    "_ = plot_roc_curve(lm, X_train[['payment_delay_0']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jetzt mit Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.payment_delay_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd0_dummies = pd.get_dummies(X_train.payment_delay_0, prefix='pd0_dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd0_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariates Modell für payment_delay_0 mit Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier sehen wir durch das Binning eine (leichte) Verbesserung der AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(pd0_dummies, y_train)\n",
    "_ = plot_roc_curve(lm, pd0_dummies, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(lm.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenstellen der Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun stellen wir die neuen durch das Binning erhalten Features mit den anderen Features zusammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(X_train.sex, prefix='sex_dummy')\n",
    "education_dummies = pd.get_dummies(X_train.education, prefix='education_dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = pd.concat([sex_dummies, education_dummies, age_dummies, pd0_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir trainieren das neue Modell und sehen eine deutliche Verbesserung der AUC auf nun 73% (gegenüber 65% ohne Binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm = LogisticRegression(solver='liblinear')\n",
    "lm.fit(X_features, y_train)\n",
    "_ = plot_roc_curve(lm, X_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validierung auf Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir überprüfen nun, ob das Modell auch auf den unabhängigen Testdaten ähnlich gute Qualität hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_test = pd.read_csv(dataset_path + '/finance/credit card defaults_test.csv')\n",
    "ds_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entsprechend müssen wir nun sämtliche Schritte der Vorverarbeitung, inklusive des Binning, auf diesen Daten nachexzerzieren. In einem weniger prototypischen Code würden wir diese Verarbeitung in Funktionen kapseln und diese Redundanz vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ds_test.drop(['id', 'default'], axis=1)\n",
    "y_test = ds_test.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dummies = pd.get_dummies(X_test, columns=['education', 'sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_binned_test = np.digitize(X_test.age, [25, 30, 35, 40, 50, 60, 70])\n",
    "age_dummies_test = pd.get_dummies(age_binned_test, prefix='age_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd0_dummies_test = pd.get_dummies(X_test.payment_delay_0, prefix='pd0_dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummies_test = pd.get_dummies(X_test.sex, prefix='sex_dummy')\n",
    "education_dummies_test = pd.get_dummies(X_test.education, prefix='education_dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_test = pd.concat([sex_dummies_test, education_dummies_test, age_dummies_test, pd0_dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass die AUC mit 73% gleich hoch ist wie auf den Trainingsdaten. Es liegt also kein Overfitting vor und das Modell wurde damit erfolgreich auf den Testdaten validiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plot_roc_curve(lm, X_features_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktive ROC-Kurve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden interaktiven Grafik kann die Funktionsweise der AUC nachvollzogen werden. Durch den Regler verändert man den Schwellwert, der zwischen Ausfällen und Nicht-Ausfällen trennt. Mit niedrigerem Schwellwert hat man mehr korrekt positive, aber auch mehr falsch positive Vorhersagen. Wenn man all diese Punktepaare aus korrekt positiven und falsch positiven Anteilen aufträgt, erhält man die Receiver Operating Characteristic (ROC). Die Fläche unter dieser Kurve ist die Area Under Curve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm.predict_proba(X_features_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred)\n",
    "thresholds_rev = list(reversed(thresholds))\n",
    "roc_auc = roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_with_threshold(thr):\n",
    "    i = max(bisect.bisect_right(thresholds_rev, thr), 1)\n",
    "    i = len(thresholds_rev) - i\n",
    "\n",
    "    pred_discrete = pred > thr\n",
    "    cm = np.pad(confusion_matrix(y_test, pred_discrete), (0, 1))\n",
    "    cm[2] = cm.sum(axis=0)\n",
    "    cm[:, 2] = cm.sum(axis=1)\n",
    "    dfcm = pd.DataFrame(\n",
    "        cm,\n",
    "        index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive', 'Sum']]),\n",
    "        columns=pd.MultiIndex.from_product([['Model'], ['Negative', 'Positive', 'Sum']])\n",
    "    )\n",
    "    dfcm['Model', 'Positive rate'] = dfcm['Model', 'Positive'] / dfcm['Model', 'Sum']\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.scatter(fpr[i], tpr[i], c='red', s=40)\n",
    "    plt.show()\n",
    "\n",
    "    display(dfcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': '150px'}\n",
    "layout = widgets.Layout(width='400px')\n",
    "\n",
    "_ = interact(\n",
    "    roc_with_threshold,\n",
    "    thr=widgets.SelectionSlider(\n",
    "        options=np.round(np.linspace(1, 0, 101), 2),\n",
    "        description='Threshold',\n",
    "        layout=layout,\n",
    "        style=style,\n",
    "        orientation='horizontal',\n",
    "        readout=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich mit Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die logistische Regression ist ein etabliertes und leicht erklärbares Verfahren, kann jedoch in vielen Fällen nicht mit leistungsfähigeren Verfahren wie z.B. einem Random Forest mithalten. Hier erproben wir exemplarisch, wie sich ein Random Forest auf den Daten schlägt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sieht, dass der Random Forest auf den Trainingsdaten ein optimales Ergebnis erzielt. Dies ist für diese Modellklasse üblich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plot_roc_curve(rf, X_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidend ist daher die Qualität auf den Testdaten. Hier erreicht der Random Forest eine AUC von 77% und ist damit ein gutes Stück besser als die logistiche Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc_curve(rf, X_test_dummies, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich mit Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein oft noch leistungsfähigeres Verfahren sind die sogenannten Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GradientBoostingClassifier()\n",
    "gbt.fit(X_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie ein Random Forest lernen sie die Trainingsdaten auswändig. Auch hier ist also die Qualität auf den Testdaten entscheidend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_roc_curve(gbt, X_train_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit 79% AUC ist diese tatsächlich noch etwas besser als beim Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_roc_curve(gbt, X_test_dummies, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
