{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse für Kundenrezensionen\n",
    "\n",
    "Wir trainieren ein Neuronales Netzwerk darin zu erkennen, ob eine Rezension eines Kunden eher positiv oder eher negativ ausfällt.\n",
    "\n",
    "### Daten\n",
    "Der Datensatz umfasst Rezensionen von Nutzern für die DKB und für drei andere Banken, die in Webforen wie Trustpilot veröffentlicht wurden. Zusätzlich zum Text bewertet der Kunde die Bank mit 1 bis 5 Sternen. Diese Sterne werden als Label verwendet zum Trainieren des Netzwerks. Eine Rezension mit 5 Sternen gilt als positiv, eine mit einem Stern als negativ und alles dazwischen als neutral (wie wir sehen werden, vergeben die meisten Kunden entweder 1 oder 5 Sterne, sodass die Daten so einigermaßen gleichmäßig verteilt werden).\n",
    "\n",
    "### Vorverarbeitung\n",
    "Dem neuronalen Netzwerk wird ein Vorverständnis von deutscher Sprache mitgegeben. Dazu werden die Wörter aus den Rezensionen semantisch vorverarbeitet. Hierzu kommt die Bibliothek Fasttext von Facebook zum Einsatz, deren Word Embeddings benutzt werden, um die Wörter in 300-dimensionale numerische Vektoren zu transformieren. Die Dimensionen geben verschiedene Aspekte von Bedeutung und Inhalt wieder. Wörter mit ähnlicher Bedeutung liegen dabei nah beieinander. Dies wird weiter unten im Notebook an einem Beispiel gezeigt.\n",
    "\n",
    "Die Nutzung von Fasttext ist ein Beispiel für Transfer Learning.\n",
    "\n",
    "### Architektur des neuronalen Netzwerks\n",
    "Es wird ein rekurrentes neuronales Netzwerk trainiert, das Sequenzen von Wörter (den Text der Rezension) verarbeitet. In dem neuronalen Netzwerk kommen einige zusätzliche Technologien zum Einsatz wie LTSM (Long Short-Term Memory), die sich für die Verarbeitung von natürlicher Sprache bewährt haben. Diese zu erläutern, würde hier den Rahmen sprengen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst importieren wir einige Bibliotheken und Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann lesen wir die Rezensionen für DKB und anderen Banken eingeladen und die ersten Einträge angezeigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('Rezensionen 20190828.csv')\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung:** Die Rezensionen stammen aus unterschiedlichen Quellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung:** Neben der DKB gibt es auch Rezensionen für N26, ING und Comdirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.hist(column='stars', by='code', figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obigen Histogramme für jede der vier Banken, wieviele Reviews mit 1, 2, 3, 4 und 5 Sternen abgegeben wurden.\n",
    "\n",
    "**Beobachtung:** Nur wenige Kunden vergeben 2 bis 4 Sterne, die meisten vergeben entweder die Minimal- oder die Maximalwertung\n",
    "\n",
    "**Beobachtung:** ING schneidet sehr gut ab, mit vielen 5-Sterne Bewertungen, bei DKB herrscht eine negative Meinung vor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ehe wir die Texte mit einem Neuronalen Netzwerk verarbeiten, säubern wir die Daten. Dazu gehört es, Sonderzeichen und Zahlen zu entfernen, die Leerzeichen zu normalisieren etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "reviews = [text.replace('\\xa0', ' ') for text in reviews_df.text]    # fix whitespace\n",
    "reviews = [re.sub('[.,;:()\\'?\"!\\\\-]', ' ', text) for text in reviews]    # replace punctuation\n",
    "reviews = [re.sub('[0-9]+', 'NUMBER', text) for text in reviews]    # replace numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Beispiel nach der Vorverarbeitung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Verwendung der Texte in einem KI-Modell müssen wir diese numerisch kodieren. Eine Möglichkeit dafür ist TFIDF. Dabei werden Wörter entsprechend ihrer Anzahl in einem Text relativ zu ihrer Anzahl in allen Texten gewichtet. Diese Gewichtung ist dann die numerische Codierung die zum Trainieren eines KI-Modells verwendet werden kann.\n",
    "\n",
    "Wörter die in über 90% der Texte vorkommen sind nicht aussagekräftig für den Text und werden von uns daher ausgeschlossen. Wir schließen ebenfalls Wörter aus die in weniger als 10 Texten vorkommen, aus diesen kann ein KI-Modell ebenfalls nichts lernen. Von den übrigen Wörtern nehmen wir die 1000 häufigsten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "\n",
    "tfidf_encoder = sklearn.feature_extraction.text.TfidfVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=10,\n",
    "    max_df=0.9,\n",
    "    strip_accents='unicode',\n",
    "    use_idf=1,\n",
    "    smooth_idf=1,\n",
    "    sublinear_tf=1,\n",
    "    norm='l2',\n",
    "    max_features=1000,\n",
    ")\n",
    "\n",
    "tfidf_encoder.fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns jetzt anschauen wieviele Wörter ausgeschlossen wurden ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_encoder.stop_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... und welche das beispielhaft sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tfidf_encoder.stop_words_)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns nun die 1000 Wörter an die verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(sorted(tfidf_encoder.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wenden nun die numerische Codierung an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tfidf = tfidf_encoder.transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die ersten hundert Einträge in einem codierter Text sehen z.B. wie folgt aus.\n",
    "\n",
    "Dabei bekommt jedes der 1000 Wörter, das im Text nicht auftaucht eine 0. Die vorhandenen Wörter bekommen eine Zahl entsprechend der durch TFIDF festgelegten Gewichtung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tfidf[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun vergeben wir die Labels. Wie eingangs beschrieben, verwenden wir hierzu die folgende Zuordnung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_mapping = {1: 0, 2: 1, 3: 1, 4: 1, 5: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = reviews_df.stars.map(stars_mapping)\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ordnen wir die semantischen Wortvektoren, die wir bereits oben kennengelernt haben, den Wörter aus den Rezensionen zu. Wir beschränken uns dabei jeweils auf die ersten 200 Wörter einer Rezension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation des Neuronalen Netzwerks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst laden wir die nötigen Bibliotheken, um ein Neuronales Netzwerk in Python aufzusetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Code baut die Schichten des Neuronalen Netzwerks auf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(BatchNormalization(input_shape=(1000,)))\n",
    "\n",
    "#hidden layers\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001,decay=0.0001),loss=\"categorical_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion *model.summary()* überprüfen wir die Struktur des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen nun die Daten wie immer auf in Trainingsdaten und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_tfidf, to_categorical(targets), test_size=0.2, random_state=71)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt trainieren wir das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie üblich schauen wir uns die Ergebnisse an und plotten die Genauigkeiten (d.h. der Anteil derjenigen Rezensionen, bei denen die korrekte Kategorie vorhergesagt wurde) auf den Trainingsdaten und den Testdaten über die 5 Epochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit auf den Testdaten liegt bei über 80%. Die genaue Zahl berechnen wir von Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir führen das Modell auf den Testdaten aus\n",
    "scores_test = model.predict(X_test)\n",
    "pred_test = scores_test.argmax(axis=1)\n",
    "true_test = y_test.argmax(axis=1)\n",
    "\n",
    "# Wir berechnen die Anzahl der korrekten Vorhersagen und deren Prozentsatz\n",
    "correct = sum(pred_test == true_test)\n",
    "print('Test Accuracy', correct / len(pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten eine Genauigkeit von ca. 83%, was sich durchaus sehen lassen kann!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
