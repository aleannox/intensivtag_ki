{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse für Kundenrezensionen\n",
    "\n",
    "Wir trainieren ein Neuronales Netzwerk darin zu erkennen, ob eine Rezension eines Kunden eher positiv oder eher negativ ausfällt.\n",
    "\n",
    "### Daten\n",
    "Der Datensatz umfasst Rezensionen von Nutzern für die DKB und für drei andere Banken, die in Webforen wie Trustpilot veröffentlicht wurden. Zusätzlich zum Text bewertet der Kunde die Bank mit 1 bis 5 Sternen. Diese Sterne werden als Label verwendet zum Trainieren des Netzwerks. Eine Rezension mit 5 Sternen gilt als positiv, eine mit einem Stern als negativ und alles dazwischen als neutral (wie wir sehen werden, vergeben die meisten Kunden entweder 1 oder 5 Sterne, sodass die Daten so einigermaßen gleichmäßig verteilt werden).\n",
    "\n",
    "### Vorverarbeitung\n",
    "Dem neuronalen Netzwerk wird ein Vorverständnis von deutscher Sprache mitgegeben. Dazu werden die Wörter aus den Rezensionen semantisch vorverarbeitet. Hierzu kommt die Bibliothek Fasttext von Facebook zum Einsatz, deren Word Embeddings benutzt werden, um die Wörter in 300-dimensionale numerische Vektoren zu transformieren. Die Dimensionen geben verschiedene Aspekte von Bedeutung und Inhalt wieder. Wörter mit ähnlicher Bedeutung liegen dabei nah beieinander. Dies wird weiter unten im Notebook an einem Beispiel gezeigt.\n",
    "\n",
    "Die Nutzung von Fasttext ist ein Beispiel für Transfer Learning.\n",
    "\n",
    "### Architektur des neuronalen Netzwerks\n",
    "Es wird ein rekurrentes neuronales Netzwerk trainiert, das Sequenzen von Wörter (den Text der Rezension) verarbeitet. In dem neuronalen Netzwerk kommen einige zusätzliche Technologien zum Einsatz wie LTSM (Long Short-Term Memory), die sich für die Verarbeitung von natürlicher Sprache bewährt haben. Diese zu erläutern, würde hier den Rahmen sprengen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst importieren wir einige Bibliotheken und Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import plot_ROC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann lesen wir die Rezensionen für DKB und anderen Banken eingeladen und die ersten Einträge angezeigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('Rezensionen 20190828.csv')\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung:** Die Rezensionen stammen aus unterschiedlichen Quellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beobachtung:** Neben der DKB gibt es auch Rezensionen für N26, ING und Comdirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.hist(column='stars', by='code', figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obigen Histogramme für jede der vier Banken, wieviele Reviews mit 1, 2, 3, 4 und 5 Sternen abgegeben wurden.\n",
    "\n",
    "**Beobachtung:** Nur wenige Kunden vergeben 2 bis 4 Sterne, die meisten vergeben entweder die Minimal- oder die Maximalwertung\n",
    "\n",
    "**Beobachtung:** ING schneidet sehr gut ab, mit vielen 5-Sterne Bewertungen, bei DKB herrscht eine negative Meinung vor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir widmen uns nun dem eigentlichen Thema dieses Notebooks, der Sentiment-Analyse. Zentral für diese Analysen ist die FastText-Bibliothek. Sie wurde von Facebook zur Analyse natürlichsprachlicher Texte entwickelt und funktioniert besonders gut mit agglutinierenden Sprachen wie Deutsch. Wir nutzen eine Version von FastText, die auf der deutschen Wikipedia trainiert wurde. (https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.bin.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "gft_model = gensim.models.keyedvectors.FastTextKeyedVectors.load('cc.de.300.bin.gensim_model', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit FastText werden Wörter auf Basis ihrer semantischen Bedeutung numerisch kodiert. Mit dem folgenden Beispiel bekommen wir ein Gefühl für diese Funktionsweise.\n",
    "\n",
    "Dazu wählen wir ein Wort aus (im Beispiel unten 'DKB') und lassen uns von FastText die 25 ähnlichsten Wörter zurückgeben und graphisch aufbereiten.\n",
    "\n",
    "Gerne könnt ihr das auch mit anderen Wörter ausprobieren. Ein paar Beispiele zur Anregung: 'Merkel', 'zahm', 'Hund', 'iTAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_util import plot_tsne\n",
    "\n",
    "reference_word = 'DKB'\n",
    "similarities = gft_model.most_similar(positive=[reference_word], negative=[\"\"], topn=25)\n",
    "words = [word for word, _ in similarities]\n",
    "coords = [gft_model.word_vec(word) for word in words]\n",
    "plot_tsne(words, coords, perplexity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ehe wir die Texte mit Fasttext verarbeiten, säubern wir die Daten. Dazu gehört es, Sonderzeichen und Zahlen zu entfernen, die Leerzeichen zu normalisieren etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "reviews = [text.replace('\\xa0', ' ') for text in reviews_df.text]    #fix whitespace\n",
    "reviews = [re.sub('[.,;:()\\'?\"!\\\\-]', ' ', text) for text in reviews]    #replace punctuation\n",
    "reviews = [re.sub('[0-9]+', 'NUMBER', text) for text in reviews]    #replace numbers\n",
    "reviews = [[w for w in x.split(' ') if w] for x in reviews]    #split reviews in words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Beispiel nach der Vorverarbeitung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun vergeben wir die Labels. Wie eingangs beschrieben, verwenden wir hierzu die folgende Zuordnung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_mapping = {1: 0, 2: 1, 3: 1, 4: 1, 5: 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = reviews_df.stars.map(stars_mapping)\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ordnen wir die semantischen Wortvektoren, die wir bereits oben kennengelernt haben, den Wörter aus den Rezensionen zu. Wir beschränken uns dabei jeweils auf die ersten 200 Wörter einer Rezension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 200\n",
    "reviews_wv = np.zeros((len(reviews), max_review_length, 300))\n",
    "for i, r in enumerate(reviews):\n",
    "    for j, w in enumerate(r[:max_review_length]):\n",
    "        reviews_wv[i, j] = gft_model.word_vec(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation des Neuronalen Netzwerks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst laden wir die nötigen Bibliotheken, um ein Neuronales Netzwerk in Python aufzusetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional, BatchNormalization, Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Code baut die Schichten des Neuronalen Netzwerks auf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(BatchNormalization(input_shape=(200, 300, )))\n",
    "\n",
    "#hidden layers\n",
    "model.add(Bidirectional(LSTM(40)))  #optional: dropout=0.1, recurrent_dropout=0.1\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001,decay=0.0001),loss=\"categorical_crossentropy\",metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion *model.summary()* überprüfen wir die Struktur des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen nun die Daten wie immer auf in Trainingsdaten und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_wv, to_categorical(targets), test_size=0.2, random_state=71)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt trainieren wir das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie üblich schauen wir uns die Ergebnisse an und plotten die Genauigkeiten (d.h. der Anteil derjenigen Rezensionen, bei denen die korrekte Kategorie vorhergesagt wurde) auf den Trainingsdaten und den Testdaten über die 5 Epochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit auf den Testdaten liegt bei über 80%. Die genaue Zahl berechnen wir von Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir führen das Modell auf den Testdaten aus\n",
    "scores_test = model.predict(X_test)\n",
    "pred_test = scores_test.argmax(axis=1)\n",
    "true_test = y_test.argmax(axis=1)\n",
    "\n",
    "# Wir berechnen die Anzahl der korrekten Vorhersagen und deren Prozentsatz\n",
    "correct = sum(pred_test == true_test)\n",
    "print('Test Accuracy', correct / len(pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten eine Genauigkeit von ca. 83%, was sich durchaus sehen lassen kann!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
