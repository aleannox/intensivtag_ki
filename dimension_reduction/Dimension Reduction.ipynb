{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionsreduktion mit Principal Component Analysis und t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.datasets.mnist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "style = {'description_width': '150px'}\n",
    "layout = widgets.Layout(width='400px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA in zwei Dimensionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit dir das Verfahren vollständig visualisieren können, betrachten wir zuerst ein sehr einfaches Beispiel in zwei Dimensionen. Dazu erzeugen wir eine Punktewolke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "slope = np.random.uniform(-2, 2)\n",
    "x = np.random.uniform(size=100)\n",
    "y = x * slope + np.random.uniform(size=100)\n",
    "xy = np.array([x, y]).T\n",
    "xy -= xy.mean(axis=0)\n",
    "\n",
    "maxval = abs(xy).max() * 1.05\n",
    "plt.figure(figsize=[8, 8])\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "plt.xlim(-maxval, maxval)\n",
    "plt.ylim(-maxval, maxval)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun führen wir die Dimensionsreduktion mit PCA durch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "pca.fit(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren nun die dimensionreduzierten Punkte gegenüber den ursprünglichen Punkten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reduced(dim):\n",
    "    xy_reduced = np.matmul(pca.transform(xy)[:, :dim], pca.components_[:dim])\n",
    "    plt.figure(figsize=[8, 8])\n",
    "    plt.xlim(-maxval, maxval)\n",
    "    plt.ylim(-maxval, maxval)\n",
    "    plt.scatter(xy[:, 0], xy[:, 1])\n",
    "    plt.scatter(xy_reduced[:, 0], xy_reduced[:, 1], color='red')\n",
    "    var_total = (xy * xy).sum()\n",
    "    var_reduced = (xy_reduced * xy_reduced).sum()\n",
    "    plt.title(f'Percent of variance explained {var_reduced / var_total * 100:.1f}%')\n",
    "    plt.show()\n",
    "\n",
    "_ = interact(\n",
    "    plot_reduced,\n",
    "    dim=widgets.SelectionSlider(\n",
    "        options=range(0, 3),\n",
    "        description='Number of dimensions',\n",
    "        layout=layout,\n",
    "        style=style,\n",
    "        orientation='horizontal',\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA in 784 Dimensionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das folgende Beispiel ist deutlich praxisrelevanter. Man muss sich allerdings etwas in das Vorgehen eindenken, da die Anzahl der Dimensionen weit über der menschlichen Fähigkeit zur Visualisierung liegt. Wir betrachten im Folgenden Pixelbilder mit 28x28 = 784 Pixeln. Für jeden Punkt liegt ein Grauwert zwischen 0 und 1 vor (0 ist schwarz, 1 ist weiß). Effektiv entsprechend diese Graubilder also 784-dimensionalen Vektoren, für die wir (mit entsprechender Abstraktion) genau so vorgehen können wie im vorhergehenden Beispiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Bilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst lesen wir die Bilder ein. Es handelt sich um 60.000 Bilder von handschriftlichen geschriebenen Ziffern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images, labels), _ = keras.datasets.mnist.load_data()\n",
    "images = 1 - (images / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verifizieren die Dimensionen der Daten. Wir sehen, dass es sich tatsächlich um 60.000 Datensätze der Dimension 28 x 28 handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren nun beispielhaft einige der Bilder. Dabei ist i ist die Anzahl des Bildes und darf zwischen 0 und 59.999 liegen. Experimentieren Sie mit verschiedenen Werten für i. Unter dem Bild wird angegeben, welche Ziffer durch das Bild dargestellt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "plt.imshow(images[i], cmap='gray')\n",
    "plt.show()\n",
    "print(f'Ziffer: {labels[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir geben nun noch gesammelt die ersten 24 Bilder aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(4, 5, figsize=(8, 6))\n",
    "for i in range(24):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionsreduktion mit PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun führen wir für die Bilder ebenfalls eine Dimensionreduktion durch. Wir beschränken uns dabei auf Bilder der Ziffern 0 und 1, damit die Ergebnisse übersichtlicher sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sie können statt 0 und 1 auch anderen Kombinationen ausprobieren, etwa [5, 6, 8] für die Ziffern 5, 6 und 8\n",
    "selection = np.isin(labels, [0, 1])\n",
    "n = selection.sum()\n",
    "images_sel = images[selection].reshape(n, 28 * 28)\n",
    "labels_sel = labels[selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren die ersten 24 Bilder aus dem eingeschränkten Datensatz. Tatsächlich sind nur Nullen und Einsen zu sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(4, 6, figsize=(8, 6))\n",
    "for i in range(24):\n",
    "    plt.subplot(4, 6, i + 1)\n",
    "    plt.imshow(images_sel[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting der PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun führen wir die PCA auf unseren Bildern durch. Wieder werden die wichtigsten Dimensionen errechnet. Diese sind nun jedoch deutlich abstrakter und nehmen die Form von \"prototypischen\" Bildern an, aus denen die ursprünglichen Bilder zusammengesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(28 * 28)\n",
    "pca.fit(images_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zuvor visualisieren wir nun den Effekt der Dimensionsreduktion. Links sind die dimensionsreduzierten Bilder zu sehen, rechts zur Referenz die Originalbilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reduced(dim):\n",
    "    images_reconstructed = pca.mean_ + np.matmul(pca.transform(images_sel)[:, :dim], pca.components_[:dim])\n",
    "    _, ax = plt.subplots(4, 10, figsize=(18, 6))\n",
    "    plt.suptitle(f'Percent of variance explained {pca.explained_variance_ratio_[:dim].sum() * 100:.1f}%')\n",
    "    for i in range(20):\n",
    "        plt.subplot(4, 11, i + 6 * (i // 5) + 1)\n",
    "        plt.imshow(images_reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(4, 11, i + 6 * (i // 5) + 7)\n",
    "        plt.imshow(images_sel[i].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "i = interact(\n",
    "    plot_reduced,\n",
    "    dim=widgets.SelectionSlider(\n",
    "        options=list(range(11)) + [20, 50, 75, 100, 200, 400, 784],\n",
    "        description='Number of dimensions',\n",
    "        continuous_update=False,\n",
    "        style=style,\n",
    "        layout=layout,\n",
    "        orientation='horizontal',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss schauen wir unter die Haube. Zuerst betrachten wir, wie das Durchschnittsbild aussieht. Dieses kennen wir schon als das Ergebnis für die Reduktion auf 0 Dimensionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pca.mean_.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und dann betrachten wir die ersten 5 Hauptkomponenten. Diese sind am besten als Differenzbilder zu verstehen, mit denen das Durchschnittsbild Stück für Stück verfeinert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(pca.components_[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionsreduktion mit t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun widmen wir uns einem weiteren Verfahren, dem t-distributed Stochastic Neighbor Embedding (t-SNE). Wohingehen die PCA ein lineares Verfahren ist, kann t-SNE hochdimensionale Strukturen deutlich flexibler abbilden. Es dient jedoch vor allem zur menschlichen Visualisierung, eine direkte Rekonstruktion der Daten wie bei der PCA ist nicht möglich. Wie zuvor beschränken wir uns auf die Ziffern 0 und 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auch hier können Sie wieder mit verschiedenen Kombinationen von Ziffern experimentieren.\n",
    "selection = np.isin(labels, [0, 1])\n",
    "n = selection.sum()\n",
    "images_sel = images[selection].reshape(n, 28 * 28)\n",
    "labels_sel = labels[selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Laufzeit von t-SNE ist etwas länger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_samples = 2000\n",
    "\n",
    "# try different values for perplexity and also n_iter\n",
    "tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n",
    "tsne_result = tsne.fit_transform(images_sel[:num_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darstellung des Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_frame = pd.DataFrame(tsne_result).assign(label=labels_sel[:num_samples])\n",
    "plt.figure(figsize=(12, 12))\n",
    "for l, g in plot_frame.groupby('label'):\n",
    "    plt.scatter(g[0], g[1], label=l)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blick auf die einzelnen Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)\n",
    "tnse_result_rescaled = tsne_result / np.abs(tsne_result).max() * 9.5\n",
    "for i in range(300):\n",
    "    pixels = images_sel[i].copy()\n",
    "    pixels[pixels > 0.99] = np.nan\n",
    "    im = OffsetImage(pixels.reshape(28, 28), cmap='gray')\n",
    "    ab = AnnotationBbox(im, tnse_result_rescaled[i], frameon=False)\n",
    "    plt.gca().add_artist(ab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
